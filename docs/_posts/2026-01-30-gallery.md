---
layout: post
title: "Google's experimental mobile app that runs advanced GenAI models (Gemini, LLaVA, PaliGemma) entirely on-device - no internet required after download, with full source code available"
image: "/assets/images/gallery-hero.jpg"
repo_url: "https://github.com/google-ai-edge/gallery"
tags: ["AndroidDev", "OnDeviceAI", "MobileDev", "Kotlin"]
date: 2026-01-30 02:01:11 +0300
---

Ever wished you could run ChatGPT-level AI directly on your phone without burning through data or worrying about privacy? Google just open-sourced their entire AI Edge Gallery app that does exactly that. This isn't a toy demo - it's a full-featured mobile app running production-grade models like Gemini Nano, LLaVA for vision tasks, and PaliGemma for multimodal interactions, all processing locally on your device.

The app showcases what's possible when you bring the cloud down to the edge: chat with AI, analyze images, process audio clips, and experiment with different prompts - all while airplane mode is on. With 15K+ stars and availability on both Google Play and TestFlight, it's clearly striking a chord with developers who want to see the future of mobile AI. The Kotlin codebase gives Android developers a masterclass in implementing on-device ML pipelines using Google's AI Edge SDK.

Whether you're building the next generation of mobile apps or just curious about how on-device AI actually works under the hood, this repository is pure gold. The fact that Google open-sourced their entire experimental app - complete with model integration, UI patterns, and optimization techniques - makes this an invaluable learning resource for any mobile developer serious about AI integration.

---

‚≠ê **Stars:** 15034  
üíª **Language:** Kotlin  
üîó **Repository:** [google-ai-edge/gallery](https://github.com/google-ai-edge/gallery)
